# 机器学习自动调参

在实际应用中，我们需要选取合适的模型，并对模型调参，得到一组合适的参数。尤其是在模型的调参阶段，需要花费大量的时间和精力，却又效率低下。但是我们可以换一个角度来看待这个问题，模型的选取，以及模型中需要调节的参数，可以看做是一组变量，模型的质量标准（比如正确率，AUC）等等可以看做是目标函数，这个问题就是超参数的优化的问题。我们可以使用搜索算法来解决。

假设有如下函数：

```
def q (args) :
    x, y = args
    return x ∗∗ 2 + y ∗∗ 2
```

该如何优化得到q最小值呢？

## 1. Hyperopt

Hyperopt提供了一个优化接口，这个接口接受一个评估函数和参数空间，能计算出参数空间内的一个点的函数值。

Hyheropt四个重要的因素：指定需要最小化的函数，搜索的空间，采样的数据集(trails database)（可选），搜索的算法（可选）。

上文提到的q即为最小化的函数。

### **Hyperopt搜索参数空间**

```
from hyperopt import hp
space = [hp.uniform(’x’, 0, 1), hp.normal(’y’, 0, 1)] # x在0-1区间内取值，y是实数
```

#### 参数空间的设置

比如优化函数q，输入`fmin(q,space=hp.uniform(‘a’,0,1))`.

- `hp.uniform`函数的第一个参数是标签，每个超参数在参数空间内必须具有独一无二的标签。`hp.uniform`指定了参数的分布。其他的参数分布比如 ：

-  `hp.choice`返回一个选项，选项可以是list或者tuple.options可以是嵌套的表达式，用于组成条件参数。  

- `hp.pchoice(label,p_options)`以一定的概率返回一个p_options的一个选项。这个选项使得函数在搜索过程中对每个选项的可能性不均匀。  

- `hp.uniform(label,low,high)`参数在low和high之间均匀分布。  
- `hp.quniform(label,low,high,q)`,参数的取值是`round(uniform(low,high)/q)*q`，适用于那些离散的取值。  
- `hp.loguniform(label,low,high)`绘制`exp(uniform(low,high))`,变量的取值范围是`[exp(low),exp(high)]` 
-  `hp.randint(label,upper)` 返回一个在`[0,upper)`前闭后开的区间内的随机整数。  搜索空间可以含有list和dictionary.

#### 使用sample函数从参数空间内采样：

```
from hyperopt import hp
list_space = [
hp.uniform(’a’, 0, 1),
hp.loguniform(’b’, 0, 1)]

tuple_space = (
hp.uniform(’a’, 0, 1),
hp.loguniform(’b’, 0, 1))

dict_space = {
’a’: hp.uniform(’a’, 0, 1),
’b’: hp.loguniform(’b’, 0, 1)}

from hyperopt.pyll.stochasti import sample
print sample(list_space)
# => [0.13, .235]
```

#### 在参数空间内使用函数：

```
from hyperopt.pyll import scope
def foo(x):
return str(x) ∗ 3
expr_space = {
’a’: 1 + hp.uniform(’a’, 0, 1),
’b’: scope.minimum(hp.loguniform(’b’, 0, 1), 10),
’c’: scope.call(foo, args=(hp.randint(’c’, 5),)),
}
```

### **指定搜索的算法**

算法也就是hyperopt的fmin函数的algo参数的取值。当前支持的算法由**随机搜索**(对应是hyperopt.rand.suggest)，**模拟退火**(对应是hyperopt.anneal.suggest)，**TPE**算法。

```
from hyperopt import hp, fmin, rand, tpe, space_eval
best = fmin(q, space, algo=rand.suggest)
print space_eval(space, best)
```

搜索算法本身也有内置的参数决定如何去优化目标函数，我们可以指定搜索算法的参数，比如针对TPE，指定jobs：

```
from functools import partial
from hyperopt import hp, fmin, tpe
algo = partial(tpe.suggest, n_startup_jobs=10)
best = fmin(q, space, algo=algo)
print space_eval(space, best)
```

### 实例

一段使用感知器判别鸢尾花数据的代码，使用的学习率是0.1,迭代40次得到了一个测试集上正确率为82%的结果。使用hyperopt优化参数，将正确率提升到了91%。

```
from sklearn import datasets
import numpy as np
from sklearn.cross_validation import train_test_split
from sklearn.metrics import accuracy_score
iris = datasets.load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)


from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
sc.fit(X_train)
X_train_std = sc.transform(X_train)
X_test_std = sc.transform(X_test)

from sklearn.linear_model import Perceptron
ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)
ppn.fit(X_train_std, y_train)

y_pred = ppn.predict(X_test_std)
print accuracy_score(y_test, y_pred)

def percept(args):
    global X_train_std,y_train,y_test
    ppn = Perceptron(n_iter=int(args["n_iter"]),eta0=args["eta"]*0.01,random_state=0)
    ppn.fit(X_train_std, y_train)
    y_pred = ppn.predict(X_test_std)
    return -accuracy_score(y_test, y_pred)

from hyperopt import fmin,tpe,hp,partial
space = {"n_iter":hp.choice("n_iter",range(30,50)),
         "eta":hp.uniform("eta",0.05,0.5)}
algo = partial(tpe.suggest,n_startup_jobs=10)
best = fmin(percept,space,algo = algo,max_evals=100)
print best
print percept(best)
#0.822222222222
#{'n_iter': 14, 'eta': 0.12877033763511717}
#-0.911111111111
```

### Hyperopt调参XGBoost

```
import xgboost as xgb
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from hyperopt import fmin, tpe, hp, partial
from sklearn import datasets

iris = datasets.load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

def GBM(argsDict):
    max_depth = argsDict['max_depth'] + 5
    n_estimators = argsDict['n_estimators'] * 5 + 50
    learning_rate = argsDict['learning_rate'] * 0.02 + 0.05
    subsample = argsDict['subsample'] * 0.1 + 0.7
    min_child_weight = argsDict["min_child_weight"] + 1
    print("max_depth:" + str(max_depth))
    print("n_estimator:" + str(n_estimators))
    print("learning_rate:" + str(learning_rate))
    print("subsample:" + str(subsample))
    print("min_child_weight:" + str(min_child_weight))
    global X_train, y_train

    gbm = xgb.XGBClassifier(
        nthread=4,  # 进程数
        max_depth=max_depth,  # 最大深度
        n_estimators=n_estimators,  # 树的数量
        learning_rate=learning_rate,  # 学习率
        subsample=subsample,  # 采样率
        min_child_weight=min_child_weight,  # 孩子数
        max_delta_step=10,  # 10步不降则停止
        num_class=3,
        eval_metric='auc',
        objective="multi:softprob"
    )

    metric = cross_val_score(gbm, X_train, y_train, cv=5).mean()
    print('----auc----', metric)
    return -metric

space = {"max_depth": hp.randint("max_depth", 15),
         "n_estimators": hp.randint("n_estimators", 10),  # [0,1,2,3,4,5] -> [50,]
         "learning_rate": hp.randint("learning_rate", 6),  # [0,1,2,3,4,5] -> 0.05,0.06
         "subsample": hp.randint("subsample", 4),  # [0,1,2,3] -> [0.7,0.8,0.9,1.0]
         "min_child_weight": hp.randint("min_child_weight", 5),  #
         }

algo = partial(tpe.suggest, n_startup_jobs=1)
best = fmin(GBM, space, algo=algo, max_evals=5)

print(best)
print(-GBM(best))
```

## 2. 贝叶斯调参

贝叶斯调参是基于高斯分布回归的。与Hyperopt不同的是它取目标函数最大化

实例： 使用贝叶斯调参优化lightGBM

```
from bayes_opt import BayesianOptimization
import lightgbm as lgb
from sklearn import datasets
from sklearn.model_selection import cross_val_score

iris = datasets.load_iris()
X = iris.data
# print(X.shape)
y = iris.target

space = {"max_depth": (3, 5),
         "num_leaves": (20, 40),
         # "n_estimators": (50, 150),  # [0,1,2,3,4,5] -> [50,]
         "learning_rate": (0.03, 0.07),  # [0,1,2,3,4,5] -> 0.05,0.06
         "subsample": (0.7, 1.0),  # [0,1,2,3] -> [0.7,0.8,0.9,1.0]
         "min_child_weight": (2, 6)  #
         }

def GBM(max_depth, num_leaves, learning_rate, subsample, min_child_weight):
    max_depth = int(max_depth)
    # n_estimators = int(n_estimators)
    min_child_weight = int(min_child_weight)
    num_leaves = int(num_leaves)

    gbm = lgb.LGBMClassifier(
        num_leaves=num_leaves,
        nthread=3,  # 进程数
        max_depth=max_depth,  # 最大深度
        # n_estimators=n_estimators,  # 树的数量
        learning_rate=learning_rate,  # 学习率
        subsample=subsample,  # 采样率
        min_child_weight=min_child_weight,  # 孩子数
        max_delta_step=10,  # 10步不降则停止
        num_class=3,
        random_state=300,
        metric='auc',
        objective="multiclass",
        silent=False

    )

    metric = cross_val_score(gbm, X, y, cv=5).mean()
    return metric


b_xgb = BayesianOptimization(GBM, space, random_state=2000)
b_xgb.maximize()
print(b_xgb.res['max']) # 获取最大化时的值和参数
```

